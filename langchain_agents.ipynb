{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f85e59a1",
   "metadata": {},
   "source": [
    "## Import Necessary Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c22bf",
   "metadata": {},
   "source": [
    "### Load Environment Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe136f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key from .env file\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "SERP_API_KEY = os.getenv(\"SERP_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a91d8",
   "metadata": {},
   "source": [
    "## Populating the Vector Database\n",
    "Check populate_vector_bd.ipynb file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1381022",
   "metadata": {},
   "source": [
    "## Memory Configuration - Short-Term and Long-Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc71c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_persist_directory=\"./Dataset/books_chroma\"\n",
    "longterm_memory_persist_dir = \"./Dataset/langchain_conversation_chroma\"\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"BAAI/llm-embedder\") # Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134139d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Memory Configuration ==================\n",
    "# Short-term memory (last 6 messages)\n",
    "short_term_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    k=3,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# Long-term memory using Chroma\n",
    "class LongTermMemory:\n",
    "    def __init__(self):\n",
    "        self.vectorstore = Chroma(\n",
    "            collection_name=\"conversation_history\",\n",
    "            persist_directory=longterm_memory_persist_dir,\n",
    "            embedding_function=embedder\n",
    "        )\n",
    "        self.retriever = self.vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "    def get_relevant_memories(self, query):\n",
    "        return self.retriever.invoke(query)\n",
    "\n",
    "    def add_memory(self, text):\n",
    "        tz_Mumbai = pytz.timezone('Asia/Kolkata')\n",
    "        datetime_Mumbai = datetime.now(tz_Mumbai)\n",
    "        self.vectorstore.add_texts(\n",
    "            texts=[text],\n",
    "            metadatas=[{\"type\": \"conversation\",\n",
    "                        \"Time Date\": str(datetime_Mumbai)}]\n",
    "        )\n",
    "\n",
    "long_term_memory = LongTermMemory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_context = long_term_memory.get_relevant_memories(\"\")\n",
    "lt_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061fede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_term_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530656b1",
   "metadata": {},
   "source": [
    "## Build Agents - Book Analysis and Internet Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Book Analysis Agent ==================\n",
    "class BookAnalysisAgent:\n",
    "    def __init__(self):        \n",
    "        # Create LangChain vectorstore\n",
    "        self.vectorstore = Chroma(persist_directory=book_persist_directory, \n",
    "                collection_name=\"Adavance_RAG_Test\",\n",
    "                embedding_function=embedder)\n",
    "        \n",
    "        self.retriever = self.vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "\n",
    "    def answer_book(self, query):\n",
    "        \"\"\"Process book queries with error handling\"\"\"\n",
    "        try:\n",
    "            docs = self.retriever.invoke(query)\n",
    "            if not docs:\n",
    "                return \"No relevant book passages found.\"\n",
    "            return \"\\n\\n\".join([f\"From {doc.metadata['title']}:\\n{doc.page_content}\" for doc in docs])\n",
    "            # print(\"\\n\")\n",
    "            # print(\"docs: \", str(docs))\n",
    "            # return docs\n",
    "        except Exception as e:\n",
    "            return f\"Book search error: {str(e)}\"\n",
    "\n",
    "# ================== Internet Search Agent ==================\n",
    "class InternetSearchAgent:\n",
    "    def __init__(self):\n",
    "        self.url = \"https://google.serper.dev/search\"\n",
    "        self.headers = {\n",
    "        'X-API-KEY': SERP_API_KEY,\n",
    "        'Content-Type': 'application/json'\n",
    "        }\n",
    "        self.history = []\n",
    "\n",
    "    def search_web(self, query):\n",
    "        \"\"\"Perform web search with error handling\"\"\"\n",
    "        try:\n",
    "            payload = json.dumps({\n",
    "                \"q\": query,\n",
    "                \"location\": \"India\",\n",
    "                \"gl\": \"in\"\n",
    "            })\n",
    "            response = requests.post(self.url, headers=self.headers, data=payload, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            self.history.append({\"query\": query, \"result\": result})\n",
    "            \n",
    "            # Extract and format relevant information\n",
    "            if 'organic' not in result:\n",
    "                return \"No relevant web results found.\"\n",
    "                \n",
    "            top_results = result['organic'][:3]\n",
    "            return \"\\n\".join([f\"{res['title']}: {res.get('snippet', '')}\" for res in top_results])\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Search error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f92bee9",
   "metadata": {},
   "source": [
    "#### Initialize agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee3f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agents\n",
    "book_agent = BookAnalysisAgent()\n",
    "internet_agent = InternetSearchAgent()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Literary Analysis\",\n",
    "        func=book_agent.answer_book,\n",
    "        description=\"Analysis of book themes and content\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Web Search\",\n",
    "        func=internet_agent.search_web,\n",
    "        description=\"Current information and general knowledge\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba40753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Agent Setup ==================\n",
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=\"\"\"Provide Detail Answer for questions using context from memories and tools. Follow these rules:\n",
    "    1. Use Literary Analysis for book-related questions.  \n",
    "    2. Use Web Search for current events/general knowledge.\n",
    "    3. Consider both conversation history and long-term memories.\n",
    "    4. Generate detailed and precise Actiona Input for Literary Analysis and Web Search.\n",
    "    5. If you not able to get the exact anwser from memories and tools reformulate the query with more details.\"\"\",\n",
    "    suffix=\"\"\"### Current Conversation:\n",
    "{chat_history}\n",
    "\n",
    "{input}\n",
    "\n",
    "{agent_scratchpad}\"\"\",\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
    ")\n",
    "\n",
    "# Initialize LLM (replace with your preferred model)\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    api_key=GROQ_API_KEY\n",
    ")\n",
    "\n",
    "# # your LCEL-style chain\n",
    "llm_chain = prompt | llm\n",
    "# new agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Create executor with combined memory handling\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=short_term_memory,\n",
    "    verbose=False,\n",
    "    max_iterations=5,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3b740",
   "metadata": {},
   "source": [
    "### Enhance Query - Add Long-Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1bc287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================== Enhanced Query Handling ==================\n",
    "# Define a function to extract the content of a message\n",
    "def process_query(query):\n",
    "    # Get relevant long-term memories\n",
    "    lt_context = \"\\n\\n\".join([doc.page_content for doc in long_term_memory.get_relevant_memories(query)])\n",
    "    # print(\"\\n\")\n",
    "    # print(\"lt_context: \",lt_context)\n",
    "    input = f\"\"\"### Long Term Memories: {lt_context}\n",
    "\n",
    "### User Question: {query}\n",
    "\"\"\"\n",
    "    # Execute agent\n",
    "    result = agent_executor.invoke({\"input\": input})\n",
    "    agent_ans = result['output'].split(\"Final Answer:\")[1].strip()\n",
    "    # Store in long-term memory\n",
    "    long_term_memory.add_memory(f\"User: {query}\\nAgent: {agent_ans}\")\n",
    "    \n",
    "    return result['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5402f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chatbot response function\n",
    "def chatbot_response(user_input):\n",
    "    # Finally, let's invoke the chain\n",
    "    response = process_query(user_input)\n",
    "    return f\"{response}\"\n",
    "\n",
    "# Create the chatbot UI\n",
    "# Text input for user messages\n",
    "user_input = widgets.Text(\n",
    "    placeholder=\"Type your message here...\",\n",
    "    description=\"You:\",\n",
    "    layout=widgets.Layout(width=\"80%\")\n",
    ")\n",
    "\n",
    "# Button to submit messages\n",
    "submit_button = widgets.Button(\n",
    "    description=\"Send\",\n",
    "    button_style=\"success\"\n",
    ")\n",
    "\n",
    "# Output area for the conversation\n",
    "output = widgets.Output(\n",
    "    layout=widgets.Layout(),\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "# Function to handle button click\n",
    "def on_submit_button_click(b):\n",
    "    with output:\n",
    "        user_message = user_input.value\n",
    "        if user_message.strip():  # Check if the input is not empty\n",
    "            # Display the user's message\n",
    "            display(HTML(f\"<strong>You:</strong> {user_message}\"))\n",
    "            \n",
    "            # Get the chatbot's response\n",
    "            bot_response = chatbot_response(user_message)\n",
    "\n",
    "            # Extract the content within the <think> tag\n",
    "            think_content = bot_response.split('Final Answer:')[0].strip()\n",
    "\n",
    "            # Extract the bot's response after the <think> tag\n",
    "            answer_content = bot_response.split('Final Answer:')[1].strip()\n",
    "\n",
    "            # Format the output\n",
    "            formatted_output = f\"\"\"\n",
    "            <strong>AskAI AgentExecutor Thinking:</strong><think style=\"font-family: 'Courier New', Courier, monospace;\">\n",
    "            > Entering new AgentExecutor chain...\n",
    "            {think_content}\n",
    "            > Finished chain.\n",
    "            </think>\n",
    "            <strong>AskAI Answer:</strong> {answer_content}\n",
    "            \"\"\"\n",
    "            # formatted_output = f\"\"\"<strong>AskAI Answer:</strong> {answer_content}\"\"\"\n",
    "            formatted_output_html = formatted_output.replace(\"\\n\", \"<br>\")\n",
    "            # Display the bot's response\n",
    "            display(HTML(f\"{formatted_output_html}\"))\n",
    "            display(HTML(\"<br>\"))\n",
    "            # Clear the input box\n",
    "            user_input.value = \"\"\n",
    "        else:\n",
    "            display(HTML(\"<em>Please enter a message.</em>\"))\n",
    "\n",
    "# Attach the function to the button's click event\n",
    "submit_button.on_click(on_submit_button_click)\n",
    "\n",
    "# Arrange the widgets vertically\n",
    "chatbot_ui = widgets.VBox([user_input, submit_button, output])\n",
    "\n",
    "# Display the chatbot UI\n",
    "display(chatbot_ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd01b9b7",
   "metadata": {},
   "source": [
    "---\n",
    "- You: What is the main theme of Verity?\n",
    "- AskAI Answer: TThe main theme of \"Verity\" by Colleen Hoover revolves around the complexity of truth, psychological manipulation, and the intricate dynamics of human relationships. The novel explores how individuals can hide their true selves, the impact of past traumas on present behavior, and the moral ambiguities that arise in personal and professional contexts. The title itself, \"Verity,\" meaning truth, underscores the journey of uncovering hidden truths about the characters and their pasts. Additionally, the book delves into themes of self-discovery and the struggle with internal demons, highlighting the darker aspects of human nature and relationships.\n",
    "---\n",
    "- You: Who murdered Megan Hipwell?\n",
    "- AskAI Answer: The murderer of Megan Hipwell is not explicitly identified in the provided documents. However, based on the context and clues, it can be inferred that her husband might be the killer, as he is a potential suspect due to the circumstances surrounding her disappearance and the mention of an affair. Answer: The murderer of Megan Hipwell is not explicitly identified in the provided context, but it is suggested that her husband might be the killer.\n",
    "---\n",
    "- You: What last 2 questions did I ask?\n",
    "- AskAI Answer: The last two questions you asked were: 1. Who murdered Megan Hipwell? 2. What is the main theme of Verity?\n",
    "---\n",
    "- You: List all my questions which I asked till now.\n",
    "- AskAI Answer: Here is a list of all the questions you've asked so far: 1. \"What is the main theme of Verity?\" 2. \"Who murdered Megan Hipwell?\" 3. \"What last 2 questions did I ask?\" 4. \"List all my questions which I asked till now.\"\n",
    "---\n",
    "- You: How many childern do Verity and Jeremy have and tell me their children names?\n",
    "- AskAI Answer: Verity and Jeremy have three children. Their daughters are named Chastin and Harper, and they also have a son named Crew.\n",
    "---\n",
    "- You: Who was Crew?\n",
    "- AskAI Answer: Crew is Jeremy's son, and he plays a significant role in the story. Crew is a young boy who has experienced traumatic events, including witnessing his sister's death and his mother's inaction during the incident. He is close to his father, Jeremy, and is part of a family that includes the narrator, who is pregnant, making Crew a big brother soon. Crew's character deals with adjusting to his new family dynamics and the emotional scars from his past.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454ef767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query execution\n",
    "# lt_context:  User: What was my previous question?\n",
    "# Agent: Your previous question was \"What is my name?\".\n",
    "\n",
    "# User: What is my name?\n",
    "# Agent: Your name is Saurabh.\n",
    "\n",
    "# User: Hi I am Saurabh\n",
    "# Agent: Hi Saurabh, how can I assist you today?\n",
    "\n",
    "# User: I like Pizza\n",
    "# Agent: Pizza is a delicious food, what's your favorite topping on a pizza?\n",
    "\n",
    "# User: How many childern do Verity and Jeremy have and tell me their children names?\n",
    "# Agent: Verity and Jeremy have two daughters, Harper and Crew.\n",
    "\n",
    "\n",
    "# query = \"Verity and Jeremy 3 childern and tell me their children names?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96262af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ree = chatbot_response(\"I like Pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c33c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412dfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1316d110",
   "metadata": {},
   "source": [
    "## Testing - Not Important\n",
    "I you are interested look for knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e7b2a",
   "metadata": {},
   "source": [
    "### long-term memory agent using - VectorStoreRetrieverMemory\n",
    "Stores the conversation history in a vector store and retrieves the most relevant parts of past conversation based on the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05257ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_vector_store = InMemoryVectorStore(embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ad072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def get_user_id(config: RunnableConfig) -> str:\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    if user_id is None:\n",
    "        raise ValueError(\"User ID needs to be provided to save a memory.\")\n",
    "    return user_id\n",
    "\n",
    "\n",
    "@tool\n",
    "def save_recall_memory(memory: str, config: RunnableConfig) -> str:\n",
    "    \"\"\"Save memory to vectorstore for later semantic retrieval.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "    document = Document(\n",
    "        page_content=memory, id=str(uuid.uuid4()), metadata={\"user_id\": user_id}\n",
    "    )\n",
    "    recall_vector_store.add_documents([document])\n",
    "    return memory\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_recall_memories(query: str, config: RunnableConfig) -> list[str]:\n",
    "    \"\"\"Search for relevant memories.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "\n",
    "    def _filter_function(doc: Document) -> bool:\n",
    "        return doc.metadata.get(\"user_id\") == user_id\n",
    "\n",
    "    documents = recall_vector_store.similarity_search(\n",
    "        query, k=3, filter=_filter_function\n",
    "    )\n",
    "    return [document.page_content for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we're specifying `user_id` to save memories for a given user\n",
    "config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}}\n",
    "memory = \"\"\n",
    "add_memories = search_recall_memories.invoke(memory, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8eb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recall_memories = search_recall_memories.invoke(convo_str, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df91e16",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7910fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ================== Memory Configuration ==================\n",
    "# # Short-term memory\n",
    "# short_term_memory = ConversationBufferMemory(\n",
    "#     memory_key=\"chat_history\",\n",
    "#     input_key=\"input\",\n",
    "#     return_messages=True\n",
    "# )\n",
    "\n",
    "# # Long-term memory configuration\n",
    "# conversation_persist_dir = \"./Dataset/conversation_chroma\"\n",
    "# conversation_vectorstore = Chroma(\n",
    "#     collection_name=\"conversation_history\",\n",
    "#     persist_directory=conversation_persist_dir,\n",
    "#     embedding_function=embedder\n",
    "# )\n",
    "# conversation_retriever = conversation_vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "# long_term_memory = VectorStoreRetrieverMemory(\n",
    "#     retriever=conversation_retriever,\n",
    "#     input_key=\"input\"\n",
    "# )\n",
    "\n",
    "# # Combined memory system\n",
    "# memory = CombinedMemory(memories=[short_term_memory, long_term_memory])\n",
    "\n",
    "# # Initialize agents\n",
    "# book_agent = BookAnalysisAgent()\n",
    "# internet_agent = InternetSearchAgent()\n",
    "\n",
    "# # Create tools\n",
    "# tools = [\n",
    "#     Tool(\n",
    "#         name=\"Book Search\",\n",
    "#         func=book_agent.answer_book,\n",
    "#         description=\"Use for questions about books, authors, or literary content\"\n",
    "#     ),\n",
    "#     Tool(\n",
    "#         name=\"Web Search\",\n",
    "#         func=internet_agent.search_web,\n",
    "#         description=\"Use for real-time information or general knowledge questions\"\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# # ================== Agent Setup ==================\n",
    "# prompt = ZeroShotAgent.create_prompt(\n",
    "#     tools,\n",
    "#     prefix=\"\"\"Answer questions using context from memories and tools. Follow these rules:\n",
    "#     1. Use Book Search for book-related questions\n",
    "#     2. Use Web Search for current events/general knowledge\n",
    "#     3. Consider both conversation history and long-term memories\"\"\",\n",
    "#     suffix=\"\"\"Long-term Context:\n",
    "# {history}\n",
    "\n",
    "# Current Conversation:\n",
    "# {chat_history}\n",
    "\n",
    "# Question: {input}\n",
    "# {agent_scratchpad}\"\"\",\n",
    "#     input_variables=[\"input\", \"chat_history\", \"history\", \"agent_scratchpad\"]\n",
    "# )\n",
    "\n",
    "# # Initialize LLM (replace with your preferred model)\n",
    "# llm = ChatGroq(\n",
    "#     temperature=0,\n",
    "#     model_name=\"llama-3.3-70b-versatile\",\n",
    "#     api_key=GROQ_API_KEY\n",
    "# )\n",
    "\n",
    "# # llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "# # agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools)\n",
    "\n",
    "# # # your LCEL-style chain\n",
    "# llm_chain = prompt | llm\n",
    "# # new agent\n",
    "# agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# # Create agent executor\n",
    "# agent_executor = AgentExecutor(\n",
    "#     agent=agent,\n",
    "#     tools=tools,\n",
    "#     memory=memory,\n",
    "#     verbose=True,\n",
    "#     max_iterations=3,\n",
    "#     handle_parsing_errors=True\n",
    "# )\n",
    "\n",
    "# Example query execution\n",
    "# query = \"What is the main theme of Verity?\"\n",
    "# result = agent_executor.invoke({\"input\": query})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
