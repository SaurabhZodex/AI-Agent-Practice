{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f85e59a1",
   "metadata": {},
   "source": [
    "## Import Necessary Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de85d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.documents import Document\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from langchain_chroma import Chroma\n",
    "from uuid import uuid4\n",
    "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c22bf",
   "metadata": {},
   "source": [
    "### Load Environment Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe136f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key from .env file\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "SERP_API_KEY = os.getenv(\"SERP_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55a91d8",
   "metadata": {},
   "source": [
    "## Populating the Vector Database\n",
    "Check populate_vector_bd.ipynb file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fe7d1f",
   "metadata": {},
   "source": [
    "## Load Vector DB or Create Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781b0cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Job\\Skill\\5. DataScience\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persist_directory=\"./Dataset/chroma_db_langchain\"\n",
    "# Embeddings\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"BAAI/llm-embedder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e9fe421",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                collection_name=\"Adavance_RAG_Test\",\n",
    "                embedding_function=embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b955a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChatGroq model\n",
    "chatgroq_model = ChatGroq(temperature=0,\n",
    "                      model_name=\"deepseek-r1-distill-qwen-32b\",\n",
    "                      api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e522d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nHello! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 6, 'total_tokens': 22, 'completion_time': 0.114285714, 'prompt_time': 0.002870991, 'queue_time': 0.051837207999999996, 'total_time': 0.117156705}, 'model_name': 'deepseek-r1-distill-qwen-32b', 'system_fingerprint': 'fp_d458a8aba5', 'finish_reason': 'stop', 'logprobs': None}, id='run-cdad4c26-e3e0-424b-a9e3-d0e4d6e5a8ac-0', usage_metadata={'input_tokens': 6, 'output_tokens': 16, 'total_tokens': 22})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import chromadb\n",
    "from datetime import datetime, timedelta\n",
    "from langchain.agents import Tool, AgentExecutor, create_structured_chat_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Initialize environment variables\n",
    "os.environ[\"SERPER_API_KEY\"] = \"your_serper_api_key\"\n",
    "OPENMETEO_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "# ================== Book Analysis Agent ==================\n",
    "class BookAnalysisAgent:\n",
    "    def __init__(self):\n",
    "        # Initialize embedding model\n",
    "        self.embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"BAAI/llm-embedder\",\n",
    "            model_kwargs={'device': 'gpu'},\n",
    "            encode_kwargs={'normalize_embeddings': True}\n",
    "        )\n",
    "        \n",
    "        # Initialize Chroma DB\n",
    "        self.client = chromadb.PersistentClient(path=\"book_db\")\n",
    "        self.collection = self.client.get_or_create_collection(\"books\")\n",
    "        \n",
    "        # Create LangChain vectorstore\n",
    "        self.vectorstore = Chroma(persist_directory=persist_directory, \n",
    "                collection_name=\"Adavance_RAG_Test\",\n",
    "                embedding_function=embedder)\n",
    "        \n",
    "        self.retriever = self.vectorstore.as_retriever()\n",
    "\n",
    "    def analyze_book(self, query):\n",
    "        docs = self.retriever.get_relevant_documents(query)\n",
    "        return \"\\n\\n\".join([f\"From {doc.metadata['title']}:\\n{doc.page_content}\" for doc in docs])\n",
    "\n",
    "# ================== Internet Search Agent ==================\n",
    "class InternetSearchAgent:\n",
    "    def __init__(self):\n",
    "        self.search = GoogleSerperAPIWrapper()\n",
    "        self.history = []\n",
    "        \n",
    "    def search_web(self, query):\n",
    "        result = self.search.run(query)\n",
    "        self.history.append({\"query\": query, \"result\": result})\n",
    "        return result\n",
    "\n",
    "# ================== Agent Orchestration ==================\n",
    "# Initialize agents\n",
    "book_agent = BookAnalysisAgent()\n",
    "search_agent = InternetSearchAgent()\n",
    "\n",
    "# Define tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Book Analysis\",\n",
    "        func=book_agent.analyze_book,\n",
    "        description=\"Analyzes books 'Verity' and 'The Girl on the Train' using vector database\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Weather Forecast\",\n",
    "        func=lambda location: weather_agent.get_weather(location),\n",
    "        description=\"Provides weather forecasts using Open-Meteo API\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Web Search\",\n",
    "        func=search_agent.search_web,\n",
    "        description=\"Searches the internet using Google via Serper API\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Set up memory and agent\n",
    "agent_kwargs = {\n",
    "    \"extra_prompt_messages\": [MessagesPlaceholder(variable_name=\"memory\")],\n",
    "    \"system_message\": SystemMessage(content=\"You are a helpful assistant with access to multiple tools.\")\n",
    "}\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"memory\", return_messages=True)\n",
    "llm = ChatOpenAI(temperature=0)  # Replace with your preferred LLM\n",
    "\n",
    "agent = create_structured_chat_agent(llm, tools, agent_kwargs)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)\n",
    "\n",
    "# ================== Usage Example ==================\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nUser: \")\n",
    "            if query.lower() in ['exit', 'quit']:\n",
    "                break\n",
    "                \n",
    "            result = agent_executor.invoke({\"input\": query})\n",
    "            print(f\"\\nAssistant: {result['output']}\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
